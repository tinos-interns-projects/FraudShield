{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211074d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1faf86e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('pay sim.csv')\n",
    "df.head()  # Replace with your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8d38e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',\n",
       "       'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud',\n",
       "       'isFlaggedFraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c135e00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6362620 entries, 0 to 6362619\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   step            int64  \n",
      " 1   type            object \n",
      " 2   amount          float64\n",
      " 3   nameOrig        object \n",
      " 4   oldbalanceOrg   float64\n",
      " 5   newbalanceOrig  float64\n",
      " 6   nameDest        object \n",
      " 7   oldbalanceDest  float64\n",
      " 8   newbalanceDest  float64\n",
      " 9   isFraud         int64  \n",
      " 10  isFlaggedFraud  int64  \n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 534.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c8fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6362620 entries, 0 to 6362619\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   step            int64  \n",
      " 1   type            object \n",
      " 2   amount          float64\n",
      " 3   nameOrig        object \n",
      " 4   oldbalanceOrg   float64\n",
      " 5   newbalanceOrig  float64\n",
      " 6   nameDest        object \n",
      " 7   oldbalanceDest  float64\n",
      " 8   newbalanceDest  float64\n",
      " 9   isFraud         int64  \n",
      " 10  isFlaggedFraud  int64  \n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 534.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd080aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding type completed.\n",
      "Label encoding nameOrig completed.\n",
      "Label encoding nameDest completed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "    print(f'Label encoding {column} completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5bd4b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6362620 entries, 0 to 6362619\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   step            int64  \n",
      " 1   type            int32  \n",
      " 2   amount          float64\n",
      " 3   nameOrig        int32  \n",
      " 4   oldbalanceOrg   float64\n",
      " 5   newbalanceOrig  float64\n",
      " 6   nameDest        int32  \n",
      " 7   oldbalanceDest  float64\n",
      " 8   newbalanceDest  float64\n",
      " 9   isFraud         int64  \n",
      " 10  isFlaggedFraud  int64  \n",
      "dtypes: float64(5), int32(3), int64(3)\n",
      "memory usage: 461.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240d2a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    6354407\n",
       "1       8213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('isFraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041bc09",
   "metadata": {},
   "source": [
    "## Isolation Forest for Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140ed527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "ROC-AUC: 0.2373\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93   1906322\n",
      "           1       0.00      0.47      0.01      2464\n",
      "\n",
      "    accuracy                           0.87   1908786\n",
      "   macro avg       0.50      0.67      0.47   1908786\n",
      "weighted avg       1.00      0.87      0.93   1908786\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1661700  244622]\n",
      " [   1313    1151]]\n",
      "\n",
      "Optimized Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00   1906322\n",
      "           1       0.00      1.00      0.00      2464\n",
      "\n",
      "    accuracy                           0.00   1908786\n",
      "   macro avg       0.50      0.50      0.00   1908786\n",
      "weighted avg       1.00      0.00      0.00   1908786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# y = df.isFraud\n",
    "# x = df.drop(columns=['isFraud'])\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x ,y,test_size = 0.3,random_state = 0)\n",
    "\n",
    "# # Fit Isolation Forest\n",
    "# iso_forest = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
    "# iso_forest.fit(x)\n",
    "\n",
    "# # Predict anomalies\n",
    "# y_pred = iso_forest.predict(x)\n",
    "\n",
    "# # Convert predictions: -1 -> fraud (1), 1 -> normal (0)\n",
    "# y_pred_converted = np.where(y_pred == -1, 1, 0)\n",
    "\n",
    "# # Accuracy\n",
    "# accuracy = accuracy_score(y, y_pred_converted)\n",
    "# print(f\"Isolation Forest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# # More metrics\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y, y_pred_converted))\n",
    "\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(confusion_matrix(y, y_pred_converted))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 1. Data Preparation\n",
    "y = df['isFraud']\n",
    "x = df.drop(columns=['isFraud'])\n",
    "\n",
    "# Split BEFORE any fitting\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain fraud ratio\n",
    ")\n",
    "\n",
    "# 2. Model Training\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=150,  # Increased from 100\n",
    "    contamination='auto',  # Let model estimate\n",
    "    max_samples=256,  # Smaller subsets reduce overfitting\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all cores\n",
    ")\n",
    "\n",
    "# Train ONLY on x_train\n",
    "iso_forest.fit(x_train)\n",
    "\n",
    "# 3. Evaluation (ONLY on test set)\n",
    "y_test_scores = iso_forest.decision_function(x_test)  # Anomaly scores\n",
    "y_test_pred = iso_forest.predict(x_test)\n",
    "\n",
    "# Convert predictions: -1 -> fraud (1), 1 -> normal (0)\n",
    "y_test_pred_converted = np.where(y_test_pred == -1, 1, 0)\n",
    "\n",
    "# 4. Proper Metrics\n",
    "print(\"Test Set Performance:\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_test_scores):.4f}\")  # Better for anomaly detection\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_converted))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_converted))\n",
    "\n",
    "# 5. Threshold Tuning (Optional)\n",
    "# Find optimal threshold based on business needs\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, -y_test_scores)  # Note: we negate scores\n",
    "\n",
    "# Example: Find threshold where recall >= 0.7\n",
    "optimal_idx = np.argmax(recalls >= 0.7)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "y_test_optimized = (-y_test_scores > optimal_threshold).astype(int)\n",
    "\n",
    "print(\"\\nOptimized Classification Report:\")\n",
    "print(classification_report(y_test, y_test_optimized))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d45e555",
   "metadata": {},
   "source": [
    "## One Class-Svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bef8bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheri\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Final Confusion Matrix:\n",
      "[[23504  1135]\n",
      " [ 1971   493]]\n",
      "\n",
      "ðŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     24639\n",
      "           1       0.30      0.20      0.24      2464\n",
      "\n",
      "    accuracy                           0.89     27103\n",
      "   macro avg       0.61      0.58      0.59     27103\n",
      "weighted avg       0.87      0.89      0.87     27103\n",
      "\n",
      "\n",
      "ðŸ’¡ Top Fraud Indicators:\n",
      "1. Balance Drop >50%: 98.6%\n",
      "2. High-Risk Recipients: 0.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE  # For balanced training\n",
    "\n",
    "# 1. Balanced Data Preparation\n",
    "fraud = df[df['isFraud'] == 1]\n",
    "normal = df[df['isFraud'] == 0].sample(len(fraud) * 10, random_state=42)  # 10:1 ratio\n",
    "df_balanced = pd.concat([fraud, normal])\n",
    "\n",
    "# 2. Enhanced Feature Engineering\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    # Transaction patterns\n",
    "    df['balance_drop_pct'] = (df['oldbalanceOrg'] - df['newbalanceOrig']) / (df['oldbalanceOrg'] + 1e-6)\n",
    "    df['recipient_risk'] = df.groupby('nameDest')['amount'].transform('count') / len(df)\n",
    "    # Time dynamics\n",
    "    df['time_since_last'] = df.groupby('nameOrig')['step'].diff().fillna(24)\n",
    "    return df\n",
    "\n",
    "X = create_features(df_balanced).drop(['isFraud','nameOrig','nameDest'], axis=1)\n",
    "y = df_balanced['isFraud']\n",
    "\n",
    "# 3. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. SMOTE Oversampling (Only on training!)\n",
    "sm = SMOTE(sampling_strategy=0.3, random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# 5. Optimized One-Class SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_res[y_res == 0])  # Train ONLY on normal\n",
    "\n",
    "svm = OneClassSVM(\n",
    "    kernel='rbf',\n",
    "    nu=0.15,  # More sensitive to outliers\n",
    "    gamma=0.001,  # Tighter decision boundary\n",
    "    cache_size=2000\n",
    ")\n",
    "svm.fit(X_train_scaled)\n",
    "\n",
    "# 6. Dynamic Thresholding\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "scores = svm.decision_function(X_test_scaled)\n",
    "\n",
    "# Find threshold where 80% of fraud is caught\n",
    "fraud_scores = scores[y_test == 1]\n",
    "threshold = np.percentile(fraud_scores, 20)  # Bottom 20% of fraud scores\n",
    "y_pred = (scores < threshold).astype(int)\n",
    "\n",
    "# 7. Evaluation\n",
    "print(\"ðŸ” Final Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nðŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Analysis\n",
    "print(\"\\nðŸ’¡ Top Fraud Indicators:\")\n",
    "print(f\"1. Balance Drop >50%: {(X_test[y_test==1]['balance_drop_pct'] > 0.5).mean():.1%}\")\n",
    "print(f\"2. High-Risk Recipients: {(X_test[y_test==1]['recipient_risk'] > 0.01).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cec0ce",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5994d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 0.0759 - val_loss: 0.0874\n",
      "Epoch 2/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0835\n",
      "Epoch 3/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.0016 - val_loss: 0.0847\n",
      "Epoch 4/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.0014 - val_loss: 0.0843\n",
      "Epoch 5/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 0.0841\n",
      "Epoch 6/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 0.0835\n",
      "Epoch 7/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 0.0844\n",
      "Epoch 8/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 0.0841\n",
      "Epoch 9/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 0.0848\n",
      "Epoch 10/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.0014 - val_loss: 0.0805\n",
      "Epoch 11/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0844\n",
      "Epoch 12/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0847\n",
      "Epoch 13/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 0.0788\n",
      "Epoch 14/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0843\n",
      "Epoch 15/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0774\n",
      "Epoch 16/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 0.0846\n",
      "Epoch 17/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0845\n",
      "Epoch 18/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0847\n",
      "Epoch 19/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0847\n",
      "Epoch 20/20\n",
      "\u001b[1m19858/19858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0787\n",
      "\u001b[1m198832/198832\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 787us/step\n",
      "Autoencoder Accuracy: 0.9735\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99   6354407\n",
      "           1       0.02      0.31      0.03      8213\n",
      "\n",
      "    accuracy                           0.97   6362620\n",
      "   macro avg       0.51      0.64      0.51   6362620\n",
      "weighted avg       1.00      0.97      0.99   6362620\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6191479  162928]\n",
      " [   5681    2532]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "y = df.isFraud\n",
    "x = df.drop(columns=['isFraud'])\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Train autoencoder only on normal (non-fraud) data\n",
    "X_train = X_scaled[y == 0]  # Only normal transactions\n",
    "\n",
    "# Autoencoder architecture\n",
    "input_dim = X_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(16, activation=\"relu\", activity_regularizer=regularizers.l1(1e-5))(input_layer)\n",
    "encoded = Dense(8, activation=\"relu\")(encoded)\n",
    "decoded = Dense(16, activation='relu')(encoded)\n",
    "output_layer = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=20,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2,\n",
    "                verbose=1)\n",
    "\n",
    "# Reconstruct full dataset\n",
    "X_reconstructed = autoencoder.predict(X_scaled)\n",
    "\n",
    "# Calculate reconstruction error\n",
    "reconstruction_error = np.mean(np.power(X_scaled - X_reconstructed, 2), axis=1)\n",
    "\n",
    "# Set threshold (mean + 3*std of normal errors is common)\n",
    "threshold = np.mean(reconstruction_error[y == 0]) + 3 * np.std(reconstruction_error[y == 0])\n",
    "\n",
    "# Predict: 1 = fraud if error > threshold\n",
    "y_pred = np.where(reconstruction_error > threshold, 1, 0)\n",
    "\n",
    "# Accuracy and Evaluation\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Autoencoder Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "826887ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('models/autoencoder.pkl', 'wb') as f:\n",
    "    pickle.dump(autoencoder, f)\n",
    "\n",
    "with open('models/oc_svm.pkl', 'wb') as f:\n",
    "    pickle.dump(svm, f)  \n",
    "\n",
    "with open('models/iso_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(iso_forest, f)          \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
